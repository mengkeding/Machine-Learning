{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST dataset classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import normalize\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in the file\n",
    "train_mat = sio.loadmat(\"train.mat\")\n",
    "print(train_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Understand the data content\n",
    "train_mat.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the training data\n",
    "data_set = train_mat['trainX']\n",
    "data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check the amount of data in the training set\n",
    "data_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shuffle the whole provided data set\n",
    "np.random.shuffle(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set aside 10000 training images as a validation set\n",
    "validation_index = np.array(random.sample(range(data_set.shape[0]), 10000))\n",
    "validation_set = data_set[validation_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Verify the validation set size\n",
    "validation_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Construct the training set\n",
    "training_data = np.delete(data_set, validation_index, 0)\n",
    "print(training_data.shape)\n",
    "\n",
    "# Separate the label and data\n",
    "training_labels = training_data[:, 784]\n",
    "training_data = training_data[:, 0:784]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize the given data\n",
    "def normalize_data(data):\n",
    "    result_data = np.zeros(data.shape)\n",
    "    for i in range(data.shape[0]):\n",
    "        result_data[i] = normalize(data[i][:,np.newaxis], axis=0).ravel()\n",
    "    return result_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate labels and data from validation_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_labels = validation_set[:, 784]\n",
    "validation_data = validation_set[:, 0:784]\n",
    "print(validation_labels.shape)\n",
    "print(validation_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalize the validation data\n",
    "norm_validation_data = normalize_data(validation_data)\n",
    "\n",
    "# Normalize the training data\n",
    "norm_training_data = normalize_data(training_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on n examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy_score = []\n",
    "training_accuracy_score = []\n",
    "def training_classifier(n, param = 1.0, l = accuracy_score, l2 = None):\n",
    "    # Get 100 training data\n",
    "    training_data1 = norm_training_data[0:n]\n",
    "    training_labels1 = training_labels[0:n]\n",
    "    # Build the SVC classifier\n",
    "    classifier1 = SVC(C = param, kernel='linear')\n",
    "    classifier1.fit(training_data1, training_labels1)\n",
    "    # Make prediction\n",
    "    score1 = classifier1.score(norm_validation_data, validation_labels)\n",
    "    l.append(score1)\n",
    "    if l2 != None:\n",
    "        score2 = classifier1.score(training_data1, training_labels1)\n",
    "        l2.append(score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_size = [100, 200, 500, 1000, 2000, 5000, 10000]\n",
    "for n in training_size:\n",
    "    training_classifier(n, l = accuracy_score, l2 = training_accuracy_score)\n",
    "print(accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the accuracy score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(training_size, accuracy_score, \"r--\", label = \"validation data set accuracy_score\")\n",
    "plt.plot(training_size, accuracy_score, \"ro\")\n",
    "plt.plot(training_size, training_accuracy_score, \"g--\", label = \"training data set accuracy_score\")\n",
    "plt.plot(training_size, training_accuracy_score, \"go\")\n",
    "plt.ylabel(\"accuracy_score\")\n",
    "plt.xlabel(\"number of training examples\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.axis([0, 11000, 0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Guess C values\n",
    "Cs = list(range(100, 10, -1)) +\\\n",
    "     [math.pow(10, 1), math.pow(10, 0), math.pow(10, -1), math.pow(10, -2),\n",
    "      math.pow(10, -3), math.pow(10, -4), math.pow(10, -5),math.pow(10, -6), \n",
    "      math.pow(10, -7),math.pow(10, -8),math.pow(10, -10), math.pow(10, -20),\n",
    "      math.pow(10, -30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tunner_with_size(n, score_list, c_s):\n",
    "    for c in c_s:\n",
    "        training_classifier(n, param = c, l = score_list)\n",
    "    if(max(score_list) > max_accuracy):\n",
    "        max_accuracy_index = scores.index(max(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tunning the hyperparameter with different training size\n",
    "sizes = [100,200,500,1000,2000,5000,10000]\n",
    "max_accuracy = 0\n",
    "max_accuracy_index = 0\n",
    "for size in sizes:\n",
    "    scores = []\n",
    "    tunner_with_size(size, scores, Cs)\n",
    "    print(size,\":\", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_c = Cs[max_accuracy_index]\n",
    "best_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in the test file\n",
    "test_mat = sio.loadmat(\"test.mat\")\n",
    "print(test_mat)\n",
    "print(test_mat.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "best_clf = SVC(C = best_c, kernel='linear')\n",
    "\n",
    "test_data = test_mat['testX']\n",
    "\n",
    "# Normalize the test data\n",
    "norm_test_data = normalize_data(test_data)\n",
    "\n",
    "best_clf.fit(training_data, training_labels)\n",
    "predictions = best_clf.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "with open('mnist_submission.csv', 'w', newline='') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerow(['Id'] + ['Category'])\n",
    "    for num in predictions:\n",
    "        writer.writerow([i] + [num])\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
